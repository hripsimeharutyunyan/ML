{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ionosphere.csv',header=None)\n",
    "df=df.drop([1], axis=1)\n",
    "df=df.drop([0], axis=1)\n",
    "#print(df.corr())\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>-0.20275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>0.89391</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>0.96510</td>\n",
       "      <td>0.03281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>0.94124</td>\n",
       "      <td>0.01766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.89724</td>\n",
       "      <td>-0.03315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>0.78735</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          2        3        4        5        6        7        8        9   \\\n",
       "0    0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000  0.03760   \n",
       "1    1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000 -0.04549   \n",
       "2    1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965  0.01198   \n",
       "3    1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000  0.00000   \n",
       "4    1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152 -0.16399   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "346  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441 -0.04622   \n",
       "347  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590  0.01606   \n",
       "348  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584  0.02446   \n",
       "349  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746  0.00110   \n",
       "350  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928 -0.09139   \n",
       "\n",
       "          10       11  ...       25       26       27       28       29  \\\n",
       "0    0.85243 -0.17755  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090   \n",
       "1    0.50874 -0.67743  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593   \n",
       "2    0.73082  0.05346  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365   \n",
       "3    0.00000  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099   \n",
       "4    0.52798 -0.20275  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "346  0.89391  0.13130  ... -0.04202  0.83479  0.00123  1.00000  0.12815   \n",
       "347  0.96510  0.03281  ...  0.01361  0.93522  0.04925  0.93159  0.08168   \n",
       "348  0.94124  0.01766  ...  0.03193  0.92489  0.02542  0.92120  0.02242   \n",
       "349  0.89724 -0.03315  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238   \n",
       "350  0.78735  0.06678  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703   \n",
       "\n",
       "          30       31       32       33  34  \n",
       "0    0.42267 -0.54487  0.18641 -0.45300   1  \n",
       "1   -0.16626 -0.06288 -0.13738 -0.02447   0  \n",
       "2    0.60436 -0.24180  0.56045 -0.38238   1  \n",
       "3    0.25682  1.00000 -0.32382  1.00000   0  \n",
       "4   -0.05707 -0.59573 -0.04608 -0.65697   1  \n",
       "..       ...      ...      ...      ...  ..  \n",
       "346  0.86660 -0.10714  0.90546 -0.04307   1  \n",
       "347  0.94066 -0.00035  0.91483  0.04712   1  \n",
       "348  0.92459  0.00442  0.92697 -0.00577   1  \n",
       "349  0.96022 -0.03757  0.87403 -0.16243   1  \n",
       "350  0.75747 -0.06678  0.85764 -0.06151   1  \n",
       "\n",
       "[351 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = 34\n",
    "df.loc[df[target_col] == 'g', 34] = 1\n",
    "df.loc[df[target_col] == 'b', 34] = 0\n",
    "df[target_col] = df[target_col].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(df[df.columns.difference([34])],df[34], test_size=0.2, random_state=49)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "xTrain=scaler.fit_transform(xTrain)\n",
    "xTest=scaler.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LDA(object):\n",
    "\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "        self.explained_variance_ = np.array([])\n",
    "        self.explained_variance_ratio_ = np.array([])\n",
    "        self.eigenvectors_ = np.array([])\n",
    "    \n",
    "    def compute_scatters(self, X, y):\n",
    "        \"\"\"\n",
    "        param X: numpy array of shape (M,N)\n",
    "        param y: numpy array of shape (M), shows to which class each row of X belongs\n",
    "        return S_w, S_b: scatter within and scatter between matrices which are of shape (N,N)\n",
    "        \"\"\"\n",
    "        S_w=np.zeros((X.shape[1],X.shape[1]))\n",
    "        S_b=np.zeros((X.shape[1],X.shape[1]))\n",
    "        mu=X.mean()\n",
    "        for i in y.unique():\n",
    "            mask=(y==i)\n",
    "            mu_i=X[mask].mean(axis=0)\n",
    "            mu=X.mean()\n",
    "            S_w+=(X[mask]-mu_i).T.dot(X[mask]-mu_i)\n",
    "            S_b+=mask.sum() * ((mu_i-mu).reshape((mu_i-mu).shape[0],1)).dot(((mu_i-mu).reshape((mu_i-mu).shape[0],1)).T)\n",
    "        return (S_w, S_b)\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        param X: numpy array of shape (M,N)\n",
    "        param y: numpy array of shape (M), shows to which class each row of X belongs\n",
    "        \"\"\"\n",
    "        \"\"\"TODO fit the model,(compute scatter matrices and compute \n",
    "        eigenvalues and eigenvectors of S_w^{-1}S_b) and update values of \n",
    "        self.explained_variance_, self.explained_variance_ratio_, self.eigenvectors\"\"\"\n",
    "        prod_matrix=np.linalg.inv(self.compute_scatters(X,y)[0]).dot(self.compute_scatters(X,y)[1])\n",
    "        eigenvalues, eigenvectors =np.linalg.eig(prod_matrix)\n",
    "        self.explained_variance_= eigenvalues.real\n",
    "        self.eigenvectors=eigenvectors\n",
    "        self.explained_variance_ratio_=self.explained_variance_ /self.explained_variance_.sum() \n",
    " \n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        param X: numpy array of shape (M,N)\n",
    "        return X_proj: numpy array of shape (M,K)\n",
    "        \"\"\"\n",
    "        \"\"\"TODO use self.explained_variance_ratio_ and self.eigenvectors_\n",
    "        to project X from dimension N to K\"\"\"\n",
    "        if self.eigenvectors.shape[0] == 0:\n",
    "            raise TypeError(\"Please fit before calling transform\")\n",
    "        explained_variance_vectors= [(np.abs( self.explained_variance_ratio_[i]), self.eigenvectors[:,i]) for i in range(len(self.explained_variance_ratio_))]\n",
    "        explained_variance_vectors=sorted(pairs, key=lambda x: x[0], reverse=True)\n",
    "        w_matrix=explained_variance_vectors[0][1].reshape(len(self.explained_variance_ratio_),1)\n",
    "        for i in range(1,self.K): \n",
    "            w_matrix =np.hstack((w_matrix,explained_variance_vectors[i][1].reshape(len(self.explained_variance_ratio_),1)))\n",
    "        X_proj = np.array(X.dot(w_matrix.real))\n",
    "        return X_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((280, 4), (280, 32))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1=LDA(K=4)\n",
    "lda1.fit(xTrain,yTrain)\n",
    "lda1.transform(xTrain).shape, xTrain.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda1.explained_variance_ratio_\n",
    "expl_var_rat_lda=lda1.explained_variance_ratio_\n",
    "var_rat1 = []\n",
    "for var_mem in expl_var_rat_lda:\n",
    "    var_rat1.append(var_mem)\n",
    "    if sum(var_rat1)>=0.90:\n",
    "        break\n",
    "\n",
    "k1=len(var_rat1)\n",
    "k1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
